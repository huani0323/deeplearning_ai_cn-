{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过LSTM网络改进Jazz Solo\n",
    "\n",
    "欢迎来到本周的最后编程任务！ 在本笔记本中，您将实现一个使用LSTM生成音乐的模型。 您甚至可以在作业结束时听自己的音乐。\n",
    "\n",
    "**您将学习：**\n",
    "- 将LSTM应用于音乐生成。\n",
    "- 通过深度学习生成自己的爵士音乐。\n",
    "\n",
    "请运行以下单元格以加载此作业中所需的所有软件包。 这可能需要几分钟的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 问题陈述\n",
    "\n",
    "您想专门为朋友的生日创作爵士音乐。 但是，您不知道任何乐器或音乐作品。 幸运的是，您了解深度学习并且可以使用LSTM网络来解决此问题。\n",
    "\n",
    "您将训练一个网络，以代表已表演作品的风格生成新颖的爵士独奏。\n",
    "\n",
    "<img src=\"images/jazz.jpg\" style=\"width:450;height:300px;\">\n",
    "\n",
    "\n",
    "### 1.1 - 数据集\n",
    "\n",
    "您将在爵士音乐的语料库上训练算法。 运行下面的单元格，收听训练集中的音频片段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_seq.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经对音乐数据进行了预处理，以根据音乐“值”呈现音乐数据。您可以非正式地将每个“值”视为一个音符，其中包括一个音调和一个持续时间。例如，如果您按下特定的钢琴键0.5秒钟，则您刚刚演奏了一个音符。在音乐理论中，“值”实际上比这复杂得多-具体来说，它还捕获了同时演奏多个音符所需的信息。例如，演奏音乐作品时，您可以同时按下两个钢琴键（同时演奏多个音符会产生所谓的“和弦”）。但是我们无需担心音乐理论的细节。出于此分配的目的，您需要知道的是，我们将获取值的数据集，并将学习RNN模型以生成值序列。\n",
    "\n",
    "我们的音乐生成系统将使用78个唯一值。运行以下代码以加载原始音乐数据并将其预处理为值。这可能需要几分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('shape of X:', X.shape)\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您刚刚加载了以下内容：\n",
    "\n",
    "- `X`：这是一个(m, $T_x$, 78)维数组。我们有m个训练示例，每个训练示例都是$T_x =30$音乐值的摘要。在每个时间步长处，输入都是78个不同的可能值之一，表示为一个热向量。因此，例如，X[i,t,:]是一个热向量，表示在时间t处第i个示例的值。\n",
    "\n",
    "- `Y`：本质上与`X`相同，但向左（过去）移了一步。与恐龙相似，我们对使用先前值预测下一个值的网络感兴趣，因此，给定x langle1时，我们的序列模型将尝试预测$y^{\\langle t \\rangle}$ 时，我们的序列模型将尝试预测 $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$。但是，将 `Y`中的数据重新排序为维度$(T_y, m, 78)$，其中$T_y = T_x$。这种格式使以后提供给LSTM更方便。\n",
    "\n",
    "- `n_values`：该数据集中唯一值的数量。应该是78。\n",
    "\n",
    "- `indices_values`：python字典，从0-77映射到音乐值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of our model\n",
    "\n",
    "这是我们将使用的模型的体系结构。 这与您在上一个笔记本中使用的Dinosaurus模型相似，不同之处在于您将在Keras中实现它。 架构如下：\n",
    "\n",
    "<img src=\"images/music_generation.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "<!--\n",
    "<img src=\"images/djmodel.png\" style=\"width:600;height:400px;\">\n",
    "<br>\n",
    "<caption><center> **Figure 1**: LSTM model. $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, ..., x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\\langle t \\rangle}$ is an index corresponding to a value (ex: \"A,0.250,< m2,P-4 >\") while $\\hat{y}$ is the prediction for the next value  </center></caption>\n",
    "!--> \n",
    "\n",
    "我们将在更长的音乐片段中随机抽取30个值的片段来训练模型。 因此，我们不必费心设置第一个输入$x^{\\langle 1 \\rangle} = \\vec{0}$，因为我们现在大部分代码段都用它来表示恐龙名称的开头。 音频开始于一段音乐的中间。 我们将每个片段设置为具有相同的长度$T_x = 30$ ，以使向量化更加容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 建立模型\n",
    "\n",
    "在这一部分中，您将构建和训练一个学习音乐模式的模型。 为此，您需要构建一个模型，该模型采用形状为$(T_x, m, 78)$的X和形状为$(m, T_y, 78)$的Y。 我们将使用具有64维隐藏状态的LSTM。 让我们设置 `n_a = 64`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这是创建具有多个输入和输出的Keras模型的方法。如果您正在构建RNN，即使在测试时间，整个输入序列$x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle T_x \\rangle}$都是*预先给定*，例如，如果输入是单词，而输出是标签，则Keras具有简单的内置函数来构建模型。但是，对于序列生成，在测试时我们并不预先知道$x^{\\langle t\\rangle}$的所有值；相反，我们使用$x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$一次生成一个。因此，代码会更加复杂，并且您将需要实现自己的for循环来迭代不同的时间步长。\n",
    "\n",
    "函数`djmodel()`将使用for循环调用LSTM层$T_x$次，重要的是所有$T_x$副本具有相同的权重。也就是说，它不应该每次都重新初始化权重-$T_x$步骤应具有权重。在Keras中实现可共享权重的图层的关键步骤是：\n",
    "1. 定义图层对象（为此，我们将使用全局变量）。\n",
    "2. 在传播输入时调用这些对象。\n",
    "\n",
    "我们已将所需的图层对象定义为全局变量。请运行下一个单元格以创建它们。请检查Keras文档以确保您了解这些层是什么：[Reshape()](https://keras.io/layers/core/#reshape)，[LSTM()](https://keras.io/layers/recurrent/#lstm), [Dense()](https://keras.io/layers/core/#dense)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshapor = Reshape((1, 78))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在， `reshapor`，`LSTM_cell`和`densor`都是层对象，您可以使用它们来实现`djmodel()`。 为了通过这些层之一传播Keras张量对象X，请使用`layer_object(X)`（如果需要多个输入，则使用 `layer_object([X,Y])`）。 例如，`reshapor(X)`将通过上面定义的 `Reshape((1,78))`层传播X。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**练习**：实现`djmodel（）`。您将需要执行2个步骤：\n",
    "\n",
    "1. 创建一个空列表“输出”以在每个时间步保存LSTM单元的输出。\n",
    "2. 循环$t \\in 1, \\ldots, T_x$：\n",
    "\n",
    "    A. 从X选择第“ t”个时间步长向量。此选择的形状应为（78，）。为此，请使用以下代码行在Keras中创建自定义 [Lambda](https://keras.io/layers/core/#lambda)层：\n",
    "```    \n",
    "           x = Lambda(lambda x: X[:,t,:])(X)\n",
    "``` \n",
    "查看Keras文档以了解其作用。它正在创建一个“临时”或“未命名”函数（Lambda函数就是该函数），以提取适当的一键热矢量，并将该函数作为Keras的 `Layer` 对象应用于 `X`。\n",
    "\n",
    "    B.将x重塑为（1,78）。您可能会发现`reshapor（）`层（在下面定义）很有用。\n",
    "\n",
    "    C.运行x通过LSTM_cell的一个步骤。记住要使用上一步的隐藏状态$a$和单元状态$c$初始化LSTM_cell。使用以下格式：\n",
    "```python\n",
    "a, _, c = LSTM_cell(input_x, initial_state=[previous hidden state, previous cell state])\n",
    "```\n",
    "\n",
    "    D.使用`densor`通过密实+ softmax层传播LSTM的输出激活值。\n",
    "    \n",
    "    E.将预测值追加到“输出”列表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras model with the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = None\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = None\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = None\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = None\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = None\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        None\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下单元格以定义模型。 我们将使用`Tx=30`, `n_a=64` （LSTM激活的维数）和`n_values=78`。 该单元可能需要几秒钟才能运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，您需要编译模型以进行训练。 我们将亚当和绝对交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，让LSTM的初始状态将`a0`和`c0`初始化为零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们拟合模型！ 由于成本函数希望以这种格式提供 `Y`（每个时间步一个列表项），因此我们将 `Y`变成一个列表。 因此， `list(Y)`是一个包含30个项目的列表，其中每个列表项目的形状均为（60,78）。 让我们训练100个时代。 这将需要几分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您应该看到模型损失减少。 现在您已经训练了一个模型，让我们继续最后一部分以实现推理算法并生成一些音乐！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 生成音乐\n",
    "\n",
    "您现在拥有一个受过训练的模型，该模型已经了解了爵士独奏者的模式。现在让我们使用此模型来合成新音乐。\n",
    "\n",
    "#### 3.1 - 预测和采样\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "在采样的每个步骤中，您将以LSTM先前状态的激活`a`和单元状态`c` 作为输入，向前传播一步，并获得新的输出激活以及单元状态。然后，可以像以前一样使用`densor`来使用新的激活 `a` 来生成输出。\n",
    "\n",
    "首先，我们将初始化 `x0`以及LSTM激活，并将像元值`a0`和`c0`初始化为零。\n",
    "\n",
    "\n",
    "<！-\n",
    "您将要构建一个函数来为您进行此推断。您的函数将采用您以前的模型以及要采样的时间步长`Ty`。它将返回一个可以为您生成序列的keras模型。此外，该功能包含`78`个单位的密集层和激活次数。\n",
    "！->\n",
    "\n",
    "\n",
    "**练习：**实施以下功能，以采样一系列音乐值。这是在生成TyTy输出字符的for循环中需要实现的一些关键步骤：\n",
    "\n",
    "步骤2.A：使用`LSTM_Cell`，它输入上一步的`c`和`a`来生成当前步骤的`c`和`a`。\n",
    "\n",
    "步骤2.B：使用`densor`（先前定义）在`a`上计算softmax，以获取当前步骤的输出。\n",
    "\n",
    "步骤2.C：通过将刚刚生成的输出附加到`outputs`中来保存。\n",
    "\n",
    "步骤2.D：将x采样为“出局”的单行本（预测），以便将其传递到下一个LSTM步骤。我们已经提供了使用 [Lambda](https://keras.io/layers/core/#lambda) 。\n",
    "```python\n",
    "x = Lambda(one_hot)(out) \n",
    "```\n",
    "[次要技术说明：这行代码不是根据`out`中的概率随机采样一个值，而是使用argmax实际上在每一步选择一个最可能的注释。]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, umber of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = None\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(None):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = None\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = None\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        None\n",
    "        \n",
    "        # Step 2.D: Select the next value according to \"out\", and set \"x\" to be the one-hot representation of the\n",
    "        #           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided \n",
    "        #           the line of code you need to do this. \n",
    "        x = None\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的单元格以定义您的推理模型。 该模型经过硬编码以生成50个值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，这将创建零值向量，用于初始化`x`和LSTM状态变量`a`和`c`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 78))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**：实现`predict_and_sample（）`。 此函数接受许多参数，包括输入[x_initializer, a_initializer, c_initializer].。 为了预测与此输入对应的输出，您将需要执行3个步骤：\n",
    "1.根据您的输入集，使用推理模型预测输出。 输出`pred`应该是长度为20的列表，其中每个元素都是一个形状为($T_y$, n_values)的numpy数组。\n",
    "2.将`pred`转换为$T_y$索引的numpy数组。 通过使用`pred`列表中元素的`argmax`来计算每个对应的索引。 [Hint](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html)。\n",
    "3.将索引转换为一键向量表示。 [Hint](https://keras.io/utils/#to_categorical)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = None\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = None\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )\n",
    "    results = None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**: 您的结果可能会有所不同，因为Keras的结果并非完全可预测。 但是，如果您如上所述用model.fit（）将LSTM_cell训练了正好100个纪元，那么您很有可能会观察到一系列不完全相同的索引。 此外，您应该注意：np.argmax（results[12]）是list（indices[12:18]）的第一个元素，np.argmax（results[17]）是list（indices[12:18]）的最后一个元素 。\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[12])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        1\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[12])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        42\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **list(indices[12:18])** =\n",
    "        </td>\n",
    "        <td>\n",
    "            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - 生成音乐\n",
    "\n",
    "最后，您准备好生成音乐了。您的RNN会生成一个值序列。以下代码通过首先调用您的`predict_and_sample（）`函数来生成音乐。然后将这些值后期处理成和弦（意味着可以同时演奏多个值或音符）。\n",
    "\n",
    "大多数计算音乐算法都使用某些后处理，因为没有这种后处理很难生成听起来不错的音乐。后处理通过确保同一声音不会重复太多，两个连续的音符彼此之间的音高相距不远等来清理生成的音频。有人可能会说，其中许多后处理步骤都是黑客。同样，许多音乐产生文学也集中于手工制作后处理器，并且许多输出质量取决于后处理的质量，而不仅仅是RNN的质量。但是这种后处理的确有很大的不同，因此也请在我们的实现中使用它。\n",
    "\n",
    "让我们做些音乐吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下单元以生成音乐并将其记录到您的`out_stream`中。 这可能需要几分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要听音乐，请单击文件->打开...，然后转到“输出/”并下载“ my_music.midi”。 您可以使用可以读取Midi文件的应用程序在计算机上播放该文件，也可以使用免费的在线“ MIDI to mp3”转换工具之一将其转换为mp3。\n",
    "\n",
    "作为参考，这也是我们使用此算法生成的30秒音频剪辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜！\n",
    "\n",
    "您已经到了笔记本的结尾。\n",
    "\n",
    "<font color=\"blue\">\n",
    "这是您应该记住的：\n",
    "    \n",
    "- 序列模型可用于生成音乐值，然后将其后处理为Midi音乐。\n",
    "- 可以使用非常相似的模型来生成恐龙名称或生成音乐，主要区别是输入模型的输入。\n",
    "- 在Keras中，序列生成涉及定义具有共享权重的图层，然后在不同的时间步长$1, \\ldots, T_x$中重复这些步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恭喜您完成了这项任务并生成了爵士独奏！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参考**\n",
    "\n",
    "本笔记本中提出的想法主要来自以下引用的三篇计算音乐论文。 这里的实现也获得了很大的启发，并使用了Ji-Sung Kim的github存储库中的许多组件。\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- François Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)\n",
    "\n",
    "我们也感谢FrançoisGermain的宝贵反馈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
